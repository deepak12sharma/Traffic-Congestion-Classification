{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hpelm\n",
    "from sklearn.metrics import precision_recall_fscore_support,ConfusionMatrixDisplay\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D,MaxPool2D,BatchNormalization\n",
    "from keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "\n",
    "from keras.layers import Dense, Activation, Flatten,Dropout\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.graph_objs import Layout, Figure, Marker\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "NUM_CLASS = 2\n",
    "CNN_EPOCH = 10\n",
    "ELM_HIDDEN_NEURONS = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_and_labels(data_path, cates): \n",
    "  X = []\n",
    "  y = []\n",
    "  i = 0\n",
    "  for index, cate in enumerate(cates): \n",
    "    for img_name in os.listdir(data_path + cate + '/'):\n",
    "      i = i +1\n",
    "      #print(i)\n",
    "      img = cv2.imread(data_path + cate + '/' + img_name)\n",
    "      if img is not None: \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img_array = Image.fromarray(img, 'RGB')\n",
    "        \n",
    "        img_rs = img_array.resize((32,32))\n",
    "       \n",
    "        img_rs = np.array(img_rs)\n",
    "      \n",
    "        X.append(img_rs)\n",
    "        y.append(index)\n",
    "  return X, y\n",
    "def preprocess_data(X, y):\n",
    "  # convert X from list to array\n",
    "  X = np.array(X)\n",
    "  \n",
    "  # convert integer values of X into floats\n",
    "  X = X.astype(np.float32)\n",
    "\n",
    "  # normalization \n",
    "  X = X/255.0\n",
    "  \n",
    "  # one-hot encoding the labels \n",
    "  y = to_categorical(np.array(y))\n",
    "    \n",
    "  return X, y\n",
    "def cnn_generate():\n",
    "    cnn_model = Sequential()\n",
    "    cnn_model.add(Conv2D(filters=32,kernel_size=3, activation='relu',padding='same',input_shape=(32,32,3)))    \n",
    "    cnn_model.add(BatchNormalization()) \n",
    "    cnn_model.add(Conv2D(filters=32,kernel_size=3, activation='relu',padding='same'))    \n",
    "    cnn_model.add(BatchNormalization())  \n",
    "    cnn_model.add(Conv2D(filters=32,kernel_size=5, activation='relu',padding='same',strides=(2,2)))    \n",
    "    cnn_model.add(BatchNormalization())    \n",
    "    cnn_model.add(Dropout(0.5))\n",
    "\n",
    "    cnn_model.add(Conv2D(filters=64,kernel_size=3, activation='relu',padding='same'))    \n",
    "    cnn_model.add(BatchNormalization()) \n",
    "    cnn_model.add(Conv2D(filters=64,kernel_size=3, activation='relu',padding='same'))    \n",
    "    cnn_model.add(BatchNormalization()) \n",
    "    cnn_model.add(Conv2D(filters=64,kernel_size=5, activation='relu',padding='same',strides=(2,2)))    \n",
    "    cnn_model.add(BatchNormalization())     \n",
    "    cnn_model.add(Dropout(0.5))\n",
    "    \n",
    "    \n",
    "    cnn_model.add(Flatten())\n",
    "\n",
    "    cnn_model.add(Dense(256))\n",
    "    cnn_model.add(Activation('relu'))\n",
    "    cnn_model.add(Dropout(0.5))\n",
    "    \n",
    "    cnn_model.add(Dense(2, activation='softmax'))\n",
    "    opt= Adam(learning_rate=0.001)\n",
    "    #opt = SGD(lr = 0.001,decay=0.9,momentum=0.9)\n",
    "    \n",
    "    cnn_model.summary()\n",
    "    cnn_model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=['accuracy'])    \n",
    "\n",
    "    #history = cnn_model.fit(data_train_2d, target_train_oh, batch_size=20, epochs=CNN_EPOCH, verbose=1, validation_split=0.2)\n",
    "\n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, epochs, batch_size):\n",
    "  # Data generator\n",
    "  datagen = ImageDataGenerator(rotation_range = 5, width_shift_range = 0.1, height_shift_range = 0.1, \n",
    "                               horizontal_flip = True)\n",
    "  # iteration on the training set\n",
    "  it_train = datagen.flow(X_train, y_train, batch_size = batch_size)\n",
    "  # path to save checkpoint \n",
    "  path_cp = os.getcwd() + '/' + 'weights_.hdf5'\n",
    "  checkpoint_ = ModelCheckpoint(path_cp, monitor = 'loss', save_best_only = True, mode = 'auto')\n",
    "  steps = X_train.shape[0]//batch_size\n",
    "  # Fitting the model\n",
    "  history = model.fit(it_train, epochs = epochs, steps_per_epoch = steps, \n",
    "                                validation_data = (X_test, y_test), verbose = 1, \n",
    "                                callbacks = checkpoint_)\n",
    "  # Evaluating the model\n",
    "  _, acc = model.evaluate(X_test, y_test, verbose = 1)\n",
    "  print('%.3f' % (acc * 100.0))\n",
    "  p1=plt\n",
    "  p1.plot(history.history['accuracy'])\n",
    "  p1.plot(history.history['val_accuracy'])\n",
    "  p1.title('model accuracy')\n",
    "  p1.ylabel('accuracy')\n",
    "  p1.xlabel('epoch')\n",
    "  p1.legend(['train', 'test'], loc='upper left')\n",
    "  p1.show()\n",
    "\n",
    "\n",
    "  p2=plt\n",
    "  #training loss vs validation loss\n",
    "  p2.plot(history.history['loss'])\n",
    "  p2.plot(history.history['val_loss'])\n",
    "  p2.title('model loss')\n",
    "  p2.ylabel('loss')\n",
    "  p2.xlabel('epoch')\n",
    "  p2.legend(['train', 'test'], loc='upper left')\n",
    "  p2.show()\n",
    "  return history, acc,model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = r\"E:\\Traffic congestion classification\\Dataset\\CNN-IELM\\train/\"\n",
    "test_path=r\"E:\\Traffic congestion classification\\Dataset\\CNN-IELM\\test/\"\n",
    "cates = ['congested','uncongested']\n",
    "#loading\n",
    "X_train, y_train = load_images_and_labels(train_path, cates)\n",
    "X_test, y_test = load_images_and_labels(test_path, cates)\n",
    "\n",
    "#loading\n",
    "X_train, y_train = load_images_and_labels(train_path, cates)\n",
    "X_test, y_test = load_images_and_labels(test_path, cates)\n",
    "\n",
    "#preprocessing\n",
    "(X_train, y_train) = preprocess_data(X_train, y_train)\n",
    "(X_test, y_test) = preprocess_data(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
